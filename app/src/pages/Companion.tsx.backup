import { useState, useRef } from "react";
import { BottomNav } from "@/components/BottomNav";
import { Button } from "@/components/ui/button";
import { Mic } from "lucide-react";

const Companion = () => {
  const [isRecording, setIsRecording] = useState(false);
  const wsRef = useRef<WebSocket | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const silenceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const audioElementRef = useRef<HTMLAudioElement | null>(null);
  const audioQueueRef = useRef<Blob[]>([]);
  const isPlayingRef = useRef(false);

  const handleSend = async () => {
    if (!input.trim()) return;

    const userMessage: Message = {
      id: `msg-${Date.now()}`,
      sender: "user",
      text: input,
      timestamp: new Date().toISOString(),
    };

    addCompanionMessage(userMessage);
    setInput("");
    setIsTyping(true);

    try {
      const response = await generateCompanionResponse([...companionMessages, userMessage], userProfile);
      
      const aiMessage: Message = {
        id: `msg-${Date.now()}-ai`,
        sender: "ai",
        text: response.text,
        timestamp: new Date().toISOString(),
      };

      addCompanionMessage(aiMessage);
      
      if (response.newTags) {
        addCompanionTags(response.newTags);
      }
    } catch (error) {
      console.error("Error generating response:", error);
    } finally {
      setIsTyping(false);
    }
  };

  const handleQuickAction = (action: string) => {
    setInput(action);
  };

  const playAudioQueue = async () => {
    console.log('playAudioQueue called, queue length:', audioQueueRef.current.length);
    
    if (audioQueueRef.current.length === 0) {
      console.log('Audio queue empty, stopping playback');
      isPlayingRef.current = false;
      setIsPlaying(false);
      return;
    }

    isPlayingRef.current = true;
    setIsPlaying(true);
    const audioBlob = audioQueueRef.current.shift()!;

    console.log('Playing audio chunk, size:', audioBlob.size, 'type:', audioBlob.type);

    try {
      const audioUrl = URL.createObjectURL(audioBlob);

      if (!audioElementRef.current) {
        audioElementRef.current = new Audio();
      }

      audioElementRef.current.src = audioUrl;

      audioElementRef.current.onended = () => {
        console.log('Audio chunk finished playing');
        URL.revokeObjectURL(audioUrl);
        playAudioQueue();
      };

      audioElementRef.current.onerror = (error) => {
        console.error('Error playing audio chunk:', error);
        URL.revokeObjectURL(audioUrl);
        playAudioQueue();
      };

      const playPromise = audioElementRef.current.play();
      if (playPromise !== undefined) {
        playPromise
          .then(() => {
            console.log('Audio playback started successfully');
          })
          .catch((error) => {
            console.error('Error starting audio playback:', error);
            URL.revokeObjectURL(audioUrl);
            playAudioQueue();
          });
      }
    } catch (error) {
      console.error('Error in playAudioQueue:', error);
      playAudioQueue();
    }
  };

  const sendAudioToServer = async (audioBlob: Blob) => {
    if (ws && ws.readyState === WebSocket.OPEN) {
      setIsTyping(true);
      const arrayBuffer = await audioBlob.arrayBuffer();
      ws.send(arrayBuffer);
    }
  };

  const handleMic = async () => {
    if (isRecording) {
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
      setIsRecording(false);
      setShouldDisconnect(true);
    } else {
      try {
        setIsRecording(true);

        const websocket = new WebSocket('ws://localhost:8000/ws/voice-chat-with-audio');

        websocket.onopen = async () => {
          console.log('WebSocket connected');

          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          let audioChunks: Blob[] = [];

          const mediaRecorder = new MediaRecorder(stream);
          mediaRecorderRef.current = mediaRecorder;

          mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
              audioChunks.push(event.data);
            }
          };

          mediaRecorder.onstop = async () => {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            await sendAudioToServer(audioBlob);

            audioChunks = [];

            if (websocket.readyState === WebSocket.OPEN && mediaRecorder) {
              mediaRecorder.start();
              setTimeout(() => {
                if (mediaRecorder.state === 'recording') {
                  mediaRecorder.stop();
                }
              }, 3000);
            } else {
              stream.getTracks().forEach(track => track.stop());
            }
          };

          mediaRecorder.start();
          setTimeout(() => {
            if (mediaRecorder.state === 'recording') {
              mediaRecorder.stop();
            }
          }, 3000);
        };

        websocket.onmessage = async (event) => {
          if (typeof event.data === 'string') {
            const message = JSON.parse(event.data);
            console.log('Received message:', message);

            if (message.type === 'transcription') {
              const userMessage: Message = {
                id: `msg-${Date.now()}`,
                sender: "user",
                text: message.text,
                timestamp: new Date().toISOString(),
              };
              addCompanionMessage(userMessage);
            } else if (message.type === 'response') {
              const aiMessage: Message = {
                id: `msg-${Date.now()}-ai`,
                sender: "ai",
                text: message.text,
                timestamp: new Date().toISOString(),
              };
              addCompanionMessage(aiMessage);
              setIsTyping(false);
            } else if (message.type === 'complete') {
              console.log('Response complete signal received');

              if (shouldDisconnect) {
                websocket.close();
                setWs(null);
                setShouldDisconnect(false);
                setIsTyping(false);
                setIsPlaying(false);
              } else if (isRecording && mediaRecorderRef.current) {
                if (mediaRecorderRef.current.state !== 'recording') {
                  mediaRecorderRef.current.start();
                  setTimeout(() => {
                    if (mediaRecorderRef.current?.state === 'recording') {
                      mediaRecorderRef.current.stop();
                    }
                  }, 3000);
                }
              }
            } else if (message.type === 'error') {
              console.error('Server error:', message.message);
              setIsTyping(false);
              setIsPlaying(false);
            }
          } else {
            console.log('Received audio chunk, size:', event.data.size);
            const audioBlob = new Blob([event.data], { type: 'audio/mpeg' });
            audioQueueRef.current.push(audioBlob);
            console.log('Audio queue length:', audioQueueRef.current.length);

            if (!isPlayingRef.current) {
              console.log('Starting audio playback');
              playAudioQueue();
            }
          }
        };

        websocket.onerror = (error) => {
          console.error('WebSocket error:', error);
          setIsTyping(false);
          setIsPlaying(false);
          setIsRecording(false);
        };

        websocket.onclose = () => {
          console.log('WebSocket disconnected');
          setIsTyping(false);
          setIsPlaying(false);
          setIsRecording(false);
          audioQueueRef.current = [];
          isPlayingRef.current = false;
        };

        setWs(websocket);
      } catch (error) {
        console.error('Error accessing microphone:', error);
        setIsRecording(false);
      }
    }
  };

  return (
    <div className="min-h-screen pb-24 flex flex-col">
      {/* Header */}
      <div className="bg-card border-b border-border sticky top-0 z-10">
        <div className="max-w-2xl mx-auto px-4 py-6 space-y-3">
          <div>
            <h1 className="text-3xl font-bold text-foreground">Narrio</h1>
            <p className="text-base text-muted-foreground">
              Private conversation, just between you and me.
            </p>
          </div>
          
          {companionTags.length > 0 && (
            <div className="flex flex-wrap gap-2">
              {companionTags.map((tag) => (
                <Badge
                  key={tag.label}
                  variant="secondary"
                  className="text-sm px-3 py-1 rounded-full"
                >
                  {tag.label}
                </Badge>
              ))}
            </div>
          )}
        </div>
      </div>

      {/* Messages */}
      <div className="flex-1 max-w-2xl mx-auto w-full px-4 py-6 space-y-6">
        {companionMessages.map((message) => (
          <div
            key={message.id}
            className={`flex ${message.sender === "user" ? "justify-end" : "justify-start"}`}
          >
            <div
              className={`max-w-[80%] rounded-2xl p-4 ${
                message.sender === "user"
                  ? "bg-primary text-primary-foreground"
                  : "bg-card border border-border"
              }`}
            >
              <p className="text-lg leading-relaxed">{message.text}</p>
            </div>
          </div>
        ))}

        {isTyping && (
          <div className="flex justify-start">
            <div className="bg-card border border-border rounded-2xl p-4">
              <div className="flex gap-2">
                <div className="w-3 h-3 rounded-full bg-muted-foreground animate-pulse" />
                <div className="w-3 h-3 rounded-full bg-muted-foreground animate-pulse" style={{ animationDelay: "0.2s" }} />
                <div className="w-3 h-3 rounded-full bg-muted-foreground animate-pulse" style={{ animationDelay: "0.4s" }} />
              </div>
            </div>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* Quick Actions */}
      <div className="max-w-2xl mx-auto w-full px-4 pb-4">
        <div className="flex flex-wrap gap-2 mb-4">
          <Button
            variant="outline"
            size="sm"
            onClick={() => handleQuickAction("I'd like to share a memory from my past")}
            className="rounded-full text-base h-10"
          >
            Share a memory
          </Button>
          <Button
            variant="outline"
            size="sm"
            onClick={() => handleQuickAction("How am I doing today?")}
            className="rounded-full text-base h-10"
          >
            How am I doing today?
          </Button>
          <Button
            variant="outline"
            size="sm"
            onClick={() => handleQuickAction("Can you suggest a Circle for me?")}
            className="rounded-full text-base h-10"
          >
            Suggest a Circle
          </Button>
        </div>

        {/* Input */}
        <div className="flex gap-2">
          <Button
            size="lg"
            variant={isRecording || isPlaying ? "default" : "outline"}
            onClick={handleMic}
            disabled={isPlaying}
            className="rounded-2xl px-4"
          >
            <Mic size={24} className={isRecording || isPlaying ? "animate-pulse" : ""} />
          </Button>
          <Input
            value={input}
            onChange={(e) => setInput(e.target.value)}
            onKeyDown={(e) => e.key === "Enter" && handleSend()}
            placeholder={isRecording ? "Recording..." : isPlaying ? "Playing response..." : "Type your message..."}
            className="text-lg h-14 rounded-2xl"
            disabled={isRecording || isPlaying}
          />
          <Button
            size="lg"
            onClick={handleSend}
            disabled={!input.trim() || isRecording || isPlaying}
            className="rounded-2xl px-6"
          >
            <Send size={24} />
          </Button>
        </div>
      </div>

      <BottomNav />
    </div>
  );
};

export default Companion;
